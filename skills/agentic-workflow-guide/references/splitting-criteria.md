# Splitting Criteria

Guide for deciding when to escalate complexity (Prompt â†’ Agent â†’ Multi-Agent) and when to split into sub-agents.

> **Key Principle:** See [design-principles.md > Simplicity First](design-principles.md#3-simplicity-first) for Anthropic's recommendation.

### Evidence Levels

| Icon | Meaning                             |
| ---- | ----------------------------------- |
| âœ…   | Official source (Anthropic, OpenAI) |
| âš ï¸   | Indirect evidence / best practice   |
| ğŸ“Š   | Community-verified (empirical)      |

> **Note on Thresholds:** Specific numeric thresholds (50 lines, 70%, etc.) are practical guidelines derived from community experience. Adjust based on your project needs. See Part 5 for customization.

---

## Part 1: Escalation Ladder

When a simple approach isn't working, escalate to the next level.

### Levels

| Level  | Configuration         | When to Use                                | Escalation Triggers (Observable Signals)                                   | Evidence |
| ------ | --------------------- | ------------------------------------------ | -------------------------------------------------------------------------- | -------- |
| **L0** | Single Prompt         | Simple Q&A, single response completes task | Same request retried 3+ times, output format unstable                      | âš ï¸       |
| **L1** | Prompt + Instructions | Repeated use, consistency needed           | Steps > 5, complex branching, **repeated "missed" or "overlooked" errors** | âš ï¸       |
| **L2** | Single Agent          | Dynamic decisions, tool use required       | Multiple responsibilities, context > 70%, phase transitions needed         | âœ… [^1]  |
| **L3** | Multi-Agent           | Complex workflows, parallel processing     | Independent subtasks, context isolation required                           | âœ… [^2]  |

> **Context Rot:** Research shows LLM performance degrades as context length increases, even on simple tasks. This supports the "context > 70%" threshold as a safety margin. [^3]

### Observable Escalation Signals

**L0 â†’ L1 (Add Instructions)**

- [ ] Same request retried 3+ times with different phrasing
- [ ] Output format varies between runs
- [ ] Need to repeat the same constraints every time

**L1 â†’ L2 (Create Agent)**

- [ ] Agent says "I missed that" or "I overlooked" something
- [ ] Later instructions in long prompts are ignored
- [ ] Need dynamic tool selection based on input
- [ ] Steps exceed 5-7 and require conditional branching
- [ ] User frequently needs to correct/redirect mid-task

**L2 â†’ L3 (Multi-Agent)**

- [ ] Single agent context exceeds 70%
- [ ] Multiple independent responsibilities that could run in parallel
- [ ] Detailed exploration pollutes main task context
- [ ] Clear phase boundaries (Plan â†’ Implement â†’ Review)

### Decision Flowchart

```
Task received
â”‚
â”œâ”€ Single LLM call sufficient?
â”‚   â”œâ”€ YES â†’ L0: Single Prompt
â”‚   â””â”€ NO â†“
â”‚
â”œâ”€ Repeated use / consistency needed?
â”‚   â”œâ”€ NO â†’ L0: Single Prompt
â”‚   â””â”€ YES â†“
â”‚
â”œâ”€ Steps â‰¤ 5 AND no complex branching?
â”‚   â”œâ”€ YES â†’ L1: Prompt + Instructions
â”‚   â””â”€ NO â†“
â”‚
â”œâ”€ Dynamic decisions / tool use needed?
â”‚   â”œâ”€ NO â†’ L1: Prompt + Instructions
â”‚   â””â”€ YES â†“
â”‚
â”œâ”€ Single responsibility AND context < 70%?
â”‚   â”œâ”€ YES â†’ L2: Single Agent
â”‚   â””â”€ NO â†’ L3: Multi-Agent
```

---

## Part 2: Sub-agent Splitting Criteria

Once at L2/L3, use these criteria to decide sub-agent boundaries.

### Quantitative Triggers

| Metric                  | Threshold              | Action                                  | Evidence |
| ----------------------- | ---------------------- | --------------------------------------- | -------- |
| **Prompt line count**   | > 50 lines             | Consider splitting                      | âš ï¸       |
| **Step count**          | > 5-7 sequential steps | Consider phase splitting                | âš ï¸       |
| **Context usage**       | > 70%                  | Mandatory: use sub-agents or compaction | âš ï¸ [^3]  |
| **Session duration**    | > 30 min               | Selective sub-agent use                 | âš ï¸       |
| **Session duration**    | > 2 hours              | Sub-agents mandatory                    | âš ï¸       |
| **Files to process**    | > 3-5 files            | File-per-subagent pattern               | ğŸ“Š [^4]  |
| **Tool calls expected** | > 15-20 calls          | Consider task splitting                 | âœ… [^2]  |
| **Subtask count**       | Dynamic/unknown        | Orchestrator-Workers pattern            | âœ… [^1]  |

### Qualitative Triggers

| Signal                     | Description                                          | Recommended Action                      |
| -------------------------- | ---------------------------------------------------- | --------------------------------------- |
| **Responsibility overlap** | One prompt has multiple independent responsibilities | Split by SRP                            |
| **Context pollution**      | Detailed exploration pollutes main task              | Isolate in sub-agent                    |
| **Parallelizable**         | Tasks can run independently                          | Parallelization or Orchestrator-Workers |
| **Phase transitions**      | Clear Plan â†’ Implement â†’ Review flow                 | Use Handoffs                            |
| **Quality loop needed**    | "Until good enough" iteration required               | Evaluator-Optimizer                     |
| **Dynamic task count**     | Subtask count depends on input                       | Orchestrator-Workers                    |
| **Input branching**        | Processing varies by input type                      | Routing                                 |

### Complexity Scaling âœ…

> **Source:** [Anthropic Multi-Agent Research System](https://www.anthropic.com/engineering/multi-agent-research-system) [^2]

| Query Complexity  | Sub-agent Count | Tool Calls per Agent       |
| ----------------- | --------------- | -------------------------- |
| Simple fact check | 1               | 3-10                       |
| Direct comparison | 2-4             | 10-15 each                 |
| Complex research  | 10+             | Clear responsibility split |

---

## Part 3: Quick Split Check

### 5-Item Checklist

Run this check when creating or reviewing prompts/agents:

```markdown
## Quick Split Check

- [ ] Prompt > 50 lines of instructions?
- [ ] More than 5-7 sequential steps?
- [ ] Multiple independent responsibilities? (SRP violation)
- [ ] Expected context usage > 70%?
- [ ] Quality loop ("until good enough") needed?

â†’ **Any YES = Consider splitting** (See Part 2 for pattern selection)
â†’ **2+ YES = Splitting recommended**
â†’ **3+ YES = Splitting mandatory**
```

### Pattern Selection Guide

| Condition                         | Recommended Pattern  |
| --------------------------------- | -------------------- |
| Tasks have clear ordering         | Prompt Chaining      |
| Tasks are independent             | Parallelization      |
| Number of tasks is dynamic        | Orchestrator-Workers |
| Repeat until quality criteria met | Evaluator-Optimizer  |
| Processing varies by input type   | Routing              |

---

## Part 4: When NOT to Split

Sub-agents have overhead. Avoid when: âœ… [^1] ğŸ“Š [^4]

> **Empirical Data:** Sub-agent overhead can be significant. In one test, sub-agents reduced main session tokens by 70% but increased total tokens by 2.4x and execution time by 6.6x. [^4]

| Scenario                    | Reason                                    | Alternative                  |
| --------------------------- | ----------------------------------------- | ---------------------------- |
| Single file, short task     | Overhead > benefit                        | Direct processing            |
| Simple Q&A                  | Overkill                                  | L0 prompt                    |
| Need follow-up conversation | Sub-agents are stateless                  | Keep in main context         |
| Context accumulation needed | Previous details lost in sub-agent return | Single agent with compaction |
| Task < 5 min expected       | Setup overhead dominates                  | Direct processing            |

### Splitting Decision Matrix

| Condition                     | Use Sub-agent? | Reason                  |
| ----------------------------- | -------------- | ----------------------- |
| Single file, < 5 min          | âŒ             | Overhead > benefit      |
| Multiple files, > 30 min      | âœ…             | Context isolation value |
| Research + Implement + Review | âœ…             | Phase separation        |
| Simple Q&A                    | âŒ             | Single call sufficient  |
| Log analysis (1000+ lines)    | âœ…             | Return only conclusions |
| Dynamic subtask discovery     | âœ…             | Orchestrator-Workers    |

---

## Part 5: Customizing Thresholds

Default thresholds can be overridden in `.github/copilot-instructions.md`:

```markdown
## Splitting Criteria Overrides

<!-- Customize thresholds for this project -->

| Metric                       | Default | Project Override |
| ---------------------------- | ------- | ---------------- |
| Prompt line threshold        | 50      | 80               |
| Step count threshold         | 5-7     | 10               |
| Context usage threshold      | 70%     | 60%              |
| Session duration (selective) | 30 min  | 45 min           |
```

---

## References

### Official Sources

[^1]: [Building Effective Agents - Anthropic](https://www.anthropic.com/engineering/building-effective-agents) â€” 5 workflow patterns, when to use agents

[^2]: [How We Built Our Multi-Agent Research System - Anthropic](https://www.anthropic.com/engineering/multi-agent-research-system) â€” Complexity scaling, sub-agent counts

[^3]: [Context Rot - Chroma Research](https://research.trychroma.com/context-rot) â€” LLM performance degrades with context length

### Community / Empirical

[^4]: [GitHub Copilot Chat ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œè¨¼ - Zenn](https://zenn.dev/openjny/articles/2619050ec7f167) â€” Overhead measurements

### Internal References

- [agent-guide.md](agent-guide.md) â€” Detailed sub-agent implementation
- [workflow-patterns/overview.md](workflow-patterns/overview.md) â€” 5 workflow patterns
- [context-engineering.md](context-engineering.md) â€” Context management techniques
